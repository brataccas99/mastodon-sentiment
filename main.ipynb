{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import pandas as panda\n",
    "from bs4 import BeautifulSoup\n",
    "from mastodon import Mastodon\n",
    "from dotenv import dotenv_values\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "env = dotenv_values()\n",
    "\n",
    "# Create an instance of the Mastodon class and authenticate\n",
    "mastodon = Mastodon(\n",
    "    access_token=env['ACCESS_TOKEN'],\n",
    "    api_base_url='https://mastodon.uno'\n",
    ")\n",
    "\n",
    "# Get the home timeline posts\n",
    "timeline = mastodon.timeline_home()\n",
    "\n",
    "# Create an instance of the SentimentIntensityAnalyzer class\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create a list to store the data for CSV\n",
    "csv_data = []\n",
    "\n",
    "# Loop through the timeline statuses\n",
    "for status in timeline:\n",
    "    content = status['content']\n",
    "    author = status['account']['username']\n",
    "    timestamp = status['created_at']\n",
    "\n",
    "    # Use BeautifulSoup to remove HTML tags from content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    filtered_content = soup.get_text()\n",
    "\n",
    "    # Remove URLs from filtered_content\n",
    "    filtered_content = re.sub(r'http\\S+|www\\S+', '', filtered_content)\n",
    "\n",
    "    # Remove only #\n",
    "    filtered_content = re.sub(r'#', '', filtered_content).lower()\n",
    "\n",
    "    # Perform sentiment analysis on the filtered content\n",
    "    sentiment_scores = analyzer.polarity_scores(filtered_content)\n",
    "    sentiment_score = sentiment_scores['compound']\n",
    "\n",
    "    # Classify sentiment based on the sentiment score\n",
    "    if sentiment_score >= 0.05:\n",
    "        sentiment_label = 'Positive'\n",
    "    elif sentiment_score <= -0.05:\n",
    "        sentiment_label = 'Negative'\n",
    "    else:\n",
    "        sentiment_label = 'Neutral'\n",
    "\n",
    "    # Add the data to csv_data as a list\n",
    "    csv_data.append([filtered_content, sentiment_label])\n",
    "\n",
    "    # Print the post information and sentiment analysis result\n",
    "    print(f\"Content: {filtered_content}\")\n",
    "    print(f\"Sentiment: {sentiment_label} ({sentiment_score})\")\n",
    "    print(\"---\")\n",
    "\n",
    "# with open('dataset.csv', 'r') as file:\n",
    "#     # Read the existing data from the CSV file\n",
    "#     existing_data = [row for row in csv.reader(file)]\n",
    "\n",
    "# # Compare the new data with the existing data\n",
    "# data_to_append = [row for row in filtered_content if row not in existing_data]\n",
    "\n",
    "# Generate csv\n",
    "with open('dataset.csv', 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Content', 'Sentiment'])  # Write the column headers\n",
    "    writer.writerows(csv_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
