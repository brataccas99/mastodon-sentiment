{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as panda\n",
    "from bs4 import BeautifulSoup\n",
    "from mastodon import Mastodon\n",
    "from dotenv import dotenv_values\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "env = dotenv_values()\n",
    "\n",
    "mastodon = Mastodon(\n",
    "    access_token=env['ACCESS_TOKEN'],\n",
    "    api_base_url='https://mastodon.uno'\n",
    ")\n",
    "\n",
    "# Create an instance of the SentimentIntensityAnalyzer class\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create a list to store the data for CSV\n",
    "csv_data = []\n",
    "\n",
    "max_id = None  # Initial value for pagination\n",
    "\n",
    "while True:\n",
    "    # Get the home timeline posts with pagination\n",
    "    timeline = mastodon.timeline_home(limit=40, max_id=max_id)\n",
    "\n",
    "    if not timeline:\n",
    "        # Break the loop if no more posts are returned\n",
    "        break\n",
    "\n",
    "    for status in timeline:\n",
    "        content = status['content']\n",
    "        author = status['account']['username']\n",
    "        timestamp = status['created_at']\n",
    "\n",
    "        # Use BeautifulSoup to remove HTML tags from content\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        filtered_content = soup.get_text()\n",
    "\n",
    "        # Remove URLs from filtered_content\n",
    "        filtered_content = re.sub(r'http\\S+|www\\S+', '', filtered_content)\n",
    "\n",
    "        # Remove only #\n",
    "        filtered_content = re.sub(r'#', '', filtered_content).lower()\n",
    "\n",
    "        # Perform sentiment analysis on the filtered content\n",
    "        sentiment_scores = analyzer.polarity_scores(filtered_content)\n",
    "        sentiment_score = sentiment_scores['compound']\n",
    "\n",
    "        # Classify sentiment based on the sentiment score\n",
    "        if sentiment_score >= 0.05:\n",
    "            sentiment_label = 'Positive'\n",
    "        elif sentiment_score <= -0.05:\n",
    "            sentiment_label = 'Negative'\n",
    "        else:\n",
    "            sentiment_label = 'Neutral'\n",
    "\n",
    "        # Add the data to csv_data as a list\n",
    "        csv_data.append([filtered_content, sentiment_label])\n",
    "\n",
    "        # Print the post information and sentiment analysis result\n",
    "        print(f\"Content: {filtered_content}\")\n",
    "        print(f\"Sentiment: {sentiment_label} ({sentiment_score})\")\n",
    "        print(\"---\")\n",
    "\n",
    "        # Update max_id for pagination\n",
    "        max_id = status['id']\n",
    "\n",
    "# Generate csv\n",
    "with open('dataset.csv', 'a', newline='', encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Content', 'Sentiment'])  # Write the column headers\n",
    "    writer.writerows(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset\n",
    "dataset = panda.read_csv(\"dataset.csv\", encoding='unicode_escape')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in bulgaria  a demon possessed priest  cursed ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volodymyr zelenskyi arrived in the czech repub...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>destroyed bts   of the armed forces of ukraine...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is no lack of threads  threadsapp  in th...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>five enemy ammunition depots destroyed in tavr...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content Sentiment\n",
       "0  in bulgaria  a demon possessed priest  cursed ...   Neutral\n",
       "1  volodymyr zelenskyi arrived in the czech repub...   Neutral\n",
       "2  destroyed bts   of the armed forces of ukraine...  Negative\n",
       "3  there is no lack of threads  threadsapp  in th...  Positive\n",
       "4  five enemy ammunition depots destroyed in tavr...  Negative"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean dataset\n",
    "\n",
    "# Removes everything that is no a text\n",
    "text_data = dataset.select_dtypes(include=['object']).applymap(\n",
    "    lambda x: re.sub(r'[^a-zA-Z]', ' ', str(x)))\n",
    "\n",
    "# Removes spaces at the beginning\n",
    "text_data = text_data.applymap(\n",
    "    lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Removes NaNs\n",
    "text_data = text_data.replace('nan', np.nan).dropna()\n",
    "\n",
    "# Exports new csv in an other csv\n",
    "text_data.to_csv(\"dataset.csv\", index=False)\n",
    "\n",
    "dataset = panda.read_csv(\"dataset.csv\", encoding='unicode_escape')\n",
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
